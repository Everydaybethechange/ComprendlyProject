{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "import spacy\n",
        "\n",
        "import torch\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Load the pre-trained NLP model from spaCy\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "# Define a function to determine if two sentences have the same meaning\n",
        "def is_same_meaning(s1, s2):\n",
        "    # Parse the two sentences using the NLP model\n",
        "    doc1 = nlp(s1)\n",
        "    doc2 = nlp(s2)\n",
        "    \n",
        "    # Calculate the similarity between the two parsed sentences\n",
        "    similarity = doc1.similarity(doc2)\n",
        "    \n",
        "    # Determine if the sentences have the same meaning based on the similarity score\n",
        "    if similarity > 0.95:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "\n",
        "# define a meaning comparison function\n",
        "def are_similar(sentence1, sentence2, threshold=0.95):\n",
        "    encoded_sentence1 = tokenizer.encode_plus(sentence1, add_special_tokens=True, return_tensors='pt')\n",
        "    encoded_sentence2 = tokenizer.encode_plus(sentence2, add_special_tokens=True, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        sentence1_output = model(encoded_sentence1['input_ids'], attention_mask=encoded_sentence1['attention_mask'])\n",
        "        sentence2_output = model(encoded_sentence2['input_ids'], attention_mask=encoded_sentence2['attention_mask'])\n",
        "    similarity = torch.cosine_similarity(sentence1_output.last_hidden_state.mean(dim=1), sentence2_output.last_hidden_state.mean(dim=1)).item()\n",
        "    print(similarity)\n",
        "    print(threshold)\n",
        "    return similarity >= threshold\n",
        "\n",
        "\n",
        "# define a function to extract nouns from a sentence\n",
        "def extract_nouns(sent):\n",
        "    tokens = nltk.word_tokenize(sent)\n",
        "    return [word for (word, pos) in nltk.pos_tag(tokens) if pos.startswith('N')]\n",
        "\n",
        "# compare not in \n",
        "def print_sentences_not_in_array(sentences, compare):\n",
        "      for sentence in sentences:\n",
        "        if sentence not in compare:\n",
        "            print(sentence)\n",
        "\n",
        "\n",
        "# input texts\n",
        "text1 = \"the cat jumped over the house. I am not tall\"\n",
        "text2 = \" I am tall. the cat jumped over a house. teri mummy.\"\n",
        "\n",
        "# tokenize into paragraphs\n",
        "sent1 = sent_tokenize(text1)\n",
        "sent2 = sent_tokenize(text2)\n",
        "\n",
        "# extract nouns for each sentence in both texts\n",
        "stripped_sentences1 = [extract_nouns(sent) for sent in sentences1]\n",
        "stripped_sentences2 = [extract_nouns(sent) for sent in sentences2]\n",
        "\n",
        "# find matched sentences between both texts\n",
        "matched_sentences = []\n",
        "for i, sent1 in enumerate(stripped_sentences1):\n",
        "    for j, sent2 in enumerate(stripped_sentences2):\n",
        "        if set(sent1) == set(sent2):\n",
        "            matched_sentences.append((sentences1[i], sentences2[j]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print matched sentences\n",
        "if matched_sentences:\n",
        "    for sent1, sent2 in matched_sentences:\n",
        "        print(f\"{sent1} <--> {sent2}\")\n",
        "        if are_similar(sent1, sent2):\n",
        "          print(\"The two sentences have the same meaning.\")\n",
        "        else:\n",
        "          print(\"The two sentences do not have the same meaning.\")\n",
        "    else:\n",
        "        print(\"No matches found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtnrTiSHmbnD",
        "outputId": "50583754-100d-4d79-b63f-09112e48ce49"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the cat jumped over the house. <--> the cat jumped over a house.\n",
            "0.9711356163024902\n",
            "0.95\n",
            "The two sentences have the same meaning.\n",
            "I am not tall <-->  I am tall.\n",
            "0.9079421162605286\n",
            "0.95\n",
            "The two sentences do not have the same meaning.\n",
            "No matches found.\n",
            "All sentences matched.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask-ngrok\n",
        "\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, request\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "@app.route('/compare-texts', methods=['POST'])\n",
        "def compare_texts():\n",
        "    text1 = request.form['text1']\n",
        "    text2 = request.form['text2']\n",
        "    \n",
        "    # logic from above would come here\n",
        "    \n",
        "    return {'output': 'your output here'}\n",
        "\n",
        "app.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpu0rQOEze7O",
        "outputId": "f0440b73-e9e9-4b22-ddc8-d113506cc23a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://94a3-35-238-39-112.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n",
            " * Running on http://94a3-35-238-39-112.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Mar/2023 20:23:42] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Mar/2023 20:23:43] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Mar/2023 20:23:52] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Mar/2023 20:23:53] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Mar/2023 20:24:17] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Mar/2023 20:34:12] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Mar/2023 20:35:47] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        }
      ]
    }
  ]
}